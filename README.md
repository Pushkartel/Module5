# CNN-based Hyperspectral Image Classification: A Comparative Study of 2D and 3D CNN Approaches on the Indian Pines Dataset

## Abstract
Hyperspectral imaging (HSI) provides rich spectral-spatial information enabling highly accurate land cover classification. However, its high dimensionality and limited labeled samples present challenges for traditional classifiers. Convolutional Neural Networks (CNNs) have shown promise for hyperspectral classification by exploiting spatial and spectral correlations.

This project presents a comparative study between **2D CNN** and **3D CNN** approaches applied to the **Indian Pines** dataset. The 2D CNN treats each spectral band as a channel in a 2D image patch, while the 3D CNN jointly models spectral and spatial dimensions using 3D convolutional filters. Experimental results demonstrate that the 3D CNN significantly improves classification accuracy and generalization, achieving higher Overall Accuracy (OA), Average Accuracy (AA), and Kappa statistics.

## 1. Introduction
Hyperspectral remote sensing captures hundreds of narrow, contiguous spectral bands for each pixel in a scene. These rich spectral signatures enable precise material identification in applications such as agriculture, mineral exploration, and environmental monitoring [1]. However, the high dimensionality and scarcity of labeled data pose significant classification challenges, known as the “Hughes phenomenon” [2].

Deep learning, particularly CNNs, addresses these issues by learning hierarchical feature representations directly from data. While **2D CNNs** primarily model spatial patterns, **3D CNNs** capture joint spectral-spatial correlations, which are crucial for HSI data. This project implements both architectures on the Indian Pines dataset to evaluate their performance.

## 2. Dataset Description
The **Indian Pines** dataset, collected by the AVIRIS sensor, contains 145 × 145 pixels with 224 spectral bands in the 0.4–2.5 μm range. After removing noisy bands, 200 bands remain. Ground truth consists of 16 land-cover classes.

**Table 1. Indian Pines Class Labels**

| Class ID | Class Name | Samples |
|----------|------------|---------|
| 1 | Alfalfa | 46 |
| 2 | Corn-notill | 1428 |
| 3 | Corn-mintill | 830 |
| 4 | Corn | 237 |
| 5 | Grass-pasture | 483 |
| 6 | Grass-trees | 730 |
| 7 | Grass-pasture-mowed | 28 |
| 8 | Hay-windrowed | 478 |
| 9 | Oats | 20 |
| 10 | Soybean-notill | 972 |
| 11 | Soybean-mintill | 2455 |
| 12 | Soybean-clean | 593 |
| 13 | Wheat | 205 |
| 14 | Woods | 1265 |
| 15 | Buildings-Grass-Trees-Drives | 386 |
| 16 | Stone-Steel-Towers | 93 |

## 3. Methodology

### 3.1 2D CNN Pipeline
- **Preprocessing**:
  - No PCA applied; original spectral bands preserved.
  - Extracted 2D spatial patches of size `windowSize × windowSize × bands`.
  - Normalized pixel values using StandardScaler.

- **Architecture**:

![2D CNN Architecture](results/2d_architecture.png)  
*Figure 1. 2D CNN architecture used for hyperspectral classification.*

- **Key Equations**:
  - Patch extraction: `Patch(i, j) = X[i - w/2 : i + w/2, j - w/2 : j + w/2, :]`
  - Convolution: `Y = X * K + b`

### 3.2 3D CNN Pipeline
- **Preprocessing**:
  - Applied PCA to reduce bands from 200 → 20 components: `Z = X × W`
    where `W` is the PCA projection matrix.
  - Extracted 3D cubes of size `windowSize × windowSize × bands`.
  - Normalized pixel values.

- **Architecture**:

![3D CNN Architecture](results/3d_architecture.png)  
*Figure 2. 3D CNN architecture used for hyperspectral classification.*

- **3D Convolution**: `Y(i, j, k) = Σ X(i+m, j+n, k+p) × K(m, n, p)`

## 4. How to Run

### 4.1 Requirements
- Python 3.8+
- TensorFlow / Keras
- scikit-learn
- spectral
- matplotlib
- seaborn

Install dependencies:
```bash
pip install -r requirements.txt
```

### 4.2 Running the 2D CNN
```bash
python train_2dcnn.py
```

### 4.3 Running the 3D CNN
```bash
python train_3dcnn.py
```

## 5. Results & Analysis

### 5.1 2D CNN Results
**Metrics**:
| Metric | Value |
|--------|-------|
| OA (%) | 92.1 |
| AA (%) | 90.4 |
| Kappa (%) | 91.5 |

![2D CNN Confusion Matrix](results/2d_confusion.png)  
*Figure 3. Confusion matrix for the 2D CNN model.*

![2D CNN Ground Truth](results/2d_gt.png)  
*Figure 4. Ground truth class map for the Indian Pines dataset (2D CNN experiment).*

![2D CNN Predicted Map](results/2d_pred.png)  
*Figure 5. Predicted class map generated by the 2D CNN.*

### 5.2 3D CNN Results
**Metrics**:
| Metric | Value |
|--------|-------|
| OA (%) | 98.2 |
| AA (%) | 97.8 |
| Kappa (%) | 98.0 |

![3D CNN Confusion Matrix](results/3d_confusion.png)  
*Figure 6. Confusion matrix for the 3D CNN model.*

![3D CNN Ground Truth](results/3d_gt.png)  
*Figure 7. Ground truth class map for the Indian Pines dataset (3D CNN experiment).*

![3D CNN Predicted Map](results/3d_pred.png)  
*Figure 8. Predicted class map generated by the 3D CNN.*

![3D CNN Training Curves](results/3d_training.png)  
*Figure 9. Training and validation accuracy/loss curves for the 3D CNN.*

## 6. Comparative Analysis
| Metric | 2D CNN | 3D CNN |
|--------|--------|--------|
| OA (%) | 92.1 | **98.2** |
| AA (%) | 90.4 | **97.8** |
| Kappa (%) | 91.5 | **98.0** |
| Training Time (s) | 230 | 540 |
| Inference Time (s) | 15 | 35 |

## 7. Conclusion & Future Work
This study demonstrates that incorporating spectral information through 3D convolution significantly improves hyperspectral image classification performance compared to 2D CNNs. The 3D CNN achieved **98.2% OA**, outperforming the 2D CNN by ~6% OA.

Future work may include:
- Incorporating attention mechanisms for adaptive spectral band weighting.
- Exploring Transformer-based architectures for HSI.
- Testing on additional benchmark datasets (Pavia University, Salinas).

## References
[1] Melgani, F., & Bruzzone, L. (2004). Classification of hyperspectral remote sensing images with support vector machines. IEEE Transactions on Geoscience and Remote Sensing.  
[2] Hughes, G. (1968). On the mean accuracy of statistical pattern recognizers. IEEE Transactions on Information Theory.
